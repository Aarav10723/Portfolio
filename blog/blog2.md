# Navigating Ethically Ambiguous Data Modeling

Data modeling is generally considered a purely technical process, with a focus on collecting data, creating a model, and validating the model's accuracy. Unfortunately, many data models operate in ethically ambiguous spaces, where harm can be done even if developers comply with laws and best practices. Ethically ambiguous data modeling refers to a situation where a data model is technically correct, but there are unresolved questions about the model's underlying assumptions, data, or consequences. Ethically ambiguous data modeling occurs not because of any wrongdoing, but because of incomplete or biased data, social inequality, and sometimes a lack of alignment between technical success and social fairness. One of the areas where ethically ambiguous data modeling occurs is with incomplete or biased data. For example, real-world data sets often lack representation of certain populations, causing a model to perform poorly on those populations but still perform well overall. Another area where ethically ambiguous data modeling occurs is with proxy variables. These are variables that indirectly include sensitive features, such as race or income, in a model. Sometimes, sensitive features may not be included in a model, but proxy variables will still include them. The last area where ethically ambiguous data modeling occurs is with a lack of alignment between a model's optimization and social fairness. Sometimes, a model may be optimized to be efficient or profitable, but it could still be unfair to a certain group of people.

In order to responsibly work through these gray areas, there are certain best practices that are important. These include data auditing and impact assessment, where certain individuals are represented and others are not. This allows data scientists to prepare for unequal impact before the model or system is implemented. Second, there is the importance of transparency and interpretability, where certain individuals are able to understand and work through the decisions made by the system. This allows for easier change if certain assumptions are harmful. 

For example, there is a credit risk model that works well in predicting default. However, the model relies heavily on past financial history. This could mean that certain individuals who are historically underserved are negatively impacted by the model. The model works well, but the social implications are ethically ambiguous.

Ethically ambiguous data modeling requires data scientists to look beyond compliance and accuracy and realize that ethics are an essential part of the work.
